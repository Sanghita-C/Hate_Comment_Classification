{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Sanghita-C/Hate_Comment_Classification/blob/main/NLP_G32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJyw9bD_TeCJ",
    "outputId": "7b3a03a6-85cf-41e0-ffb0-441c3b7f9b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\Sanghita' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PTihd0DceWnM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "KJAzSlShepO2",
    "outputId": "65d74df7-2e4c-4bce-ce5f-2378199bee92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  HS  TR  AG\n",
       "0  201  Hurray, saving us $$$ in so many ways @potus @...   1   0   0\n",
       "1  202  Why would young fighting age men be the vast m...   1   0   0\n",
       "2  203  @KamalaHarris Illegals Dump their Kids at the ...   1   0   0\n",
       "3  204  NY Times: 'Nearly All White' States Pose 'an A...   0   0   0\n",
       "4  205  Orban in Brussels: European leaders are ignori...   0   0   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv(\"hateval2019_en_train.csv\")\n",
    "df = full_df[[\"text\"]]\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wDGw-9Qlzrb"
   },
   "source": [
    "REMOVE USERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "p4akRmCRl2DE",
    "outputId": "25b75f2d-5cdc-4e8c-bbae-dc36f627bfaa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways   #LockT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>Illegals Dump their Kids at the border like R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hurray, saving us $$$ in so many ways @potus @...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2  @KamalaHarris Illegals Dump their Kids at the ...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                               tweet  \n",
       "0  Hurray, saving us $$$ in so many ways   #LockT...  \n",
       "1  Why would young fighting age men be the vast m...  \n",
       "2   Illegals Dump their Kids at the border like R...  \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...  \n",
       "4  Orban in Brussels: European leaders are ignori...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_usernames_links(tweet):\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub('http[^\\s]+','',tweet)\n",
    "    return tweet\n",
    "\n",
    "df['tweet'] = df[\"text\"].apply(remove_usernames_links)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWFwfhf3fEDv"
   },
   "source": [
    "LOWER CASING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "fymHLBkje_8b",
    "outputId": "533960a9-0e68-4590-b44a-31cdfa09e5df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways   #LockT...</td>\n",
       "      <td>hurray, saving us $$$ in so many ways   #lockt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>why would young fighting age men be the vast m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>Illegals Dump their Kids at the border like R...</td>\n",
       "      <td>illegals dump their kids at the border like r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>ny times: 'nearly all white' states pose 'an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>orban in brussels: european leaders are ignori...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hurray, saving us $$$ in so many ways @potus @...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2  @KamalaHarris Illegals Dump their Kids at the ...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Hurray, saving us $$$ in so many ways   #LockT...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2   Illegals Dump their Kids at the border like R...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                          text_lower  \n",
       "0  hurray, saving us $$$ in so many ways   #lockt...  \n",
       "1  why would young fighting age men be the vast m...  \n",
       "2   illegals dump their kids at the border like r...  \n",
       "3  ny times: 'nearly all white' states pose 'an a...  \n",
       "4  orban in brussels: european leaders are ignori...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_lower\"] = df[\"tweet\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agxBEhK8fJx3"
   },
   "source": [
    "REMOVE PUNCTUATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "aFdsR5lBfPaQ",
    "outputId": "0ce9b528-be36-4ed9-eddb-f5af1ab2afe5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways   #LockT...</td>\n",
       "      <td>hurray, saving us $$$ in so many ways   #lockt...</td>\n",
       "      <td>hurray saving us  in so many ways   lockthemup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>why would young fighting age men be the vast m...</td>\n",
       "      <td>why would young fighting age men be the vast m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>Illegals Dump their Kids at the border like R...</td>\n",
       "      <td>illegals dump their kids at the border like r...</td>\n",
       "      <td>illegals dump their kids at the border like r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>ny times: 'nearly all white' states pose 'an a...</td>\n",
       "      <td>ny times nearly all white states pose an array...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>orban in brussels: european leaders are ignori...</td>\n",
       "      <td>orban in brussels european leaders are ignorin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hurray, saving us $$$ in so many ways @potus @...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2  @KamalaHarris Illegals Dump their Kids at the ...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Hurray, saving us $$$ in so many ways   #LockT...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2   Illegals Dump their Kids at the border like R...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  hurray, saving us $$$ in so many ways   #lockt...   \n",
       "1  why would young fighting age men be the vast m...   \n",
       "2   illegals dump their kids at the border like r...   \n",
       "3  ny times: 'nearly all white' states pose 'an a...   \n",
       "4  orban in brussels: european leaders are ignori...   \n",
       "\n",
       "                                       text_wo_punct  \n",
       "0  hurray saving us  in so many ways   lockthemup...  \n",
       "1  why would young fighting age men be the vast m...  \n",
       "2   illegals dump their kids at the border like r...  \n",
       "3  ny times nearly all white states pose an array...  \n",
       "4  orban in brussels european leaders are ignorin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the new column created in last cell\n",
    "#df.drop([\"text_lower\"], axis=1, inplace=True)\n",
    "\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "df[\"text_wo_punct\"] = df['text_lower'].apply(lambda text: remove_punctuation(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayIvuxFTfW3t"
   },
   "source": [
    "STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoW-3JpOg3lZ",
    "outputId": "1941c0e4-6ec1-453c-f142-a4188014760a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sanghita chakraborty\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\sanghita chakraborty\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\sanghita chakraborty\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sanghita chakraborty\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in c:\\users\\sanghita chakraborty\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\sanghita chakraborty\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qzi6C5ung_yU",
    "outputId": "d3f508f6-279d-4580-ca17-3beb3e5c73ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sanghita\n",
      "[nltk_data]     Chakraborty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "aHW6r6LMfPfx",
    "outputId": "38176b72-bc75-4232-d6fa-501bcd35e1f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "aLR1Tqn_g3tw",
    "outputId": "35a37cfc-0d92-4594-bbf5-5d865372775b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways   #LockT...</td>\n",
       "      <td>hurray, saving us $$$ in so many ways   #lockt...</td>\n",
       "      <td>hurray saving us  in so many ways   lockthemup...</td>\n",
       "      <td>hurray saving us many ways lockthemup buildthe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>why would young fighting age men be the vast m...</td>\n",
       "      <td>why would young fighting age men be the vast m...</td>\n",
       "      <td>would young fighting age men vast majority one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>Illegals Dump their Kids at the border like R...</td>\n",
       "      <td>illegals dump their kids at the border like r...</td>\n",
       "      <td>illegals dump their kids at the border like r...</td>\n",
       "      <td>illegals dump kids border like road kill refus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>ny times: 'nearly all white' states pose 'an a...</td>\n",
       "      <td>ny times nearly all white states pose an array...</td>\n",
       "      <td>ny times nearly white states pose array proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>orban in brussels: european leaders are ignori...</td>\n",
       "      <td>orban in brussels european leaders are ignorin...</td>\n",
       "      <td>orban brussels european leaders ignoring peopl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hurray, saving us $$$ in so many ways @potus @...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2  @KamalaHarris Illegals Dump their Kids at the ...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Hurray, saving us $$$ in so many ways   #LockT...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2   Illegals Dump their Kids at the border like R...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  hurray, saving us $$$ in so many ways   #lockt...   \n",
       "1  why would young fighting age men be the vast m...   \n",
       "2   illegals dump their kids at the border like r...   \n",
       "3  ny times: 'nearly all white' states pose 'an a...   \n",
       "4  orban in brussels: european leaders are ignori...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  hurray saving us  in so many ways   lockthemup...   \n",
       "1  why would young fighting age men be the vast m...   \n",
       "2   illegals dump their kids at the border like r...   \n",
       "3  ny times nearly all white states pose an array...   \n",
       "4  orban in brussels european leaders are ignorin...   \n",
       "\n",
       "                                        text_wo_stop  \n",
       "0  hurray saving us many ways lockthemup buildthe...  \n",
       "1  would young fighting age men vast majority one...  \n",
       "2  illegals dump kids border like road kill refus...  \n",
       "3  ny times nearly white states pose array proble...  \n",
       "4  orban brussels european leaders ignoring peopl...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"text_wo_stop\"] = df[\"text_wo_punct\"].apply(lambda text: remove_stopwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twXfM95sjHmE"
   },
   "source": [
    "REMOVE URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t5_rQS0bh8LP"
   },
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "NvAsPVBmieSo",
    "outputId": "14455462-6e4a-41c0-9e2c-8118e259403c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_urlno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways   #LockT...</td>\n",
       "      <td>hurray, saving us $$$ in so many ways   #lockt...</td>\n",
       "      <td>hurray saving us  in so many ways   lockthemup...</td>\n",
       "      <td>hurray saving us many ways lockthemup buildthe...</td>\n",
       "      <td>hurray saving us many ways lockthemup buildthe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>why would young fighting age men be the vast m...</td>\n",
       "      <td>why would young fighting age men be the vast m...</td>\n",
       "      <td>would young fighting age men vast majority one...</td>\n",
       "      <td>would young fighting age men vast majority one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>Illegals Dump their Kids at the border like R...</td>\n",
       "      <td>illegals dump their kids at the border like r...</td>\n",
       "      <td>illegals dump their kids at the border like r...</td>\n",
       "      <td>illegals dump kids border like road kill refus...</td>\n",
       "      <td>illegals dump kids border like road kill refus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>ny times: 'nearly all white' states pose 'an a...</td>\n",
       "      <td>ny times nearly all white states pose an array...</td>\n",
       "      <td>ny times nearly white states pose array proble...</td>\n",
       "      <td>ny times nearly white states pose array proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>orban in brussels: european leaders are ignori...</td>\n",
       "      <td>orban in brussels european leaders are ignorin...</td>\n",
       "      <td>orban brussels european leaders ignoring peopl...</td>\n",
       "      <td>orban brussels european leaders ignoring peopl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hurray, saving us $$$ in so many ways @potus @...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2  @KamalaHarris Illegals Dump their Kids at the ...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Hurray, saving us $$$ in so many ways   #LockT...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2   Illegals Dump their Kids at the border like R...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  hurray, saving us $$$ in so many ways   #lockt...   \n",
       "1  why would young fighting age men be the vast m...   \n",
       "2   illegals dump their kids at the border like r...   \n",
       "3  ny times: 'nearly all white' states pose 'an a...   \n",
       "4  orban in brussels: european leaders are ignori...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  hurray saving us  in so many ways   lockthemup...   \n",
       "1  why would young fighting age men be the vast m...   \n",
       "2   illegals dump their kids at the border like r...   \n",
       "3  ny times nearly all white states pose an array...   \n",
       "4  orban in brussels european leaders are ignorin...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  hurray saving us many ways lockthemup buildthe...   \n",
       "1  would young fighting age men vast majority one...   \n",
       "2  illegals dump kids border like road kill refus...   \n",
       "3  ny times nearly white states pose array proble...   \n",
       "4  orban brussels european leaders ignoring peopl...   \n",
       "\n",
       "                                       text_wo_urlno  \n",
       "0  hurray saving us many ways lockthemup buildthe...  \n",
       "1  would young fighting age men vast majority one...  \n",
       "2  illegals dump kids border like road kill refus...  \n",
       "3  ny times nearly white states pose array proble...  \n",
       "4  orban brussels european leaders ignoring peopl...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_wo_urlno\"] = df[\"text_wo_stop\"].apply(lambda text: remove_urls(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JvAS01ejLiC"
   },
   "source": [
    "REMOVE HTML TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Jydj5i7KjNfP",
    "outputId": "d6c318c0-430b-4aa6-9db3-ea3d7ed34c48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_urlno</th>\n",
       "      <th>text_wo_htmlno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways   #LockT...</td>\n",
       "      <td>hurray, saving us $$$ in so many ways   #lockt...</td>\n",
       "      <td>hurray saving us  in so many ways   lockthemup...</td>\n",
       "      <td>hurray saving us many ways lockthemup buildthe...</td>\n",
       "      <td>hurray saving us many ways lockthemup buildthe...</td>\n",
       "      <td>hurray saving us many ways lockthemup buildthe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>why would young fighting age men be the vast m...</td>\n",
       "      <td>why would young fighting age men be the vast m...</td>\n",
       "      <td>would young fighting age men vast majority one...</td>\n",
       "      <td>would young fighting age men vast majority one...</td>\n",
       "      <td>would young fighting age men vast majority one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>Illegals Dump their Kids at the border like R...</td>\n",
       "      <td>illegals dump their kids at the border like r...</td>\n",
       "      <td>illegals dump their kids at the border like r...</td>\n",
       "      <td>illegals dump kids border like road kill refus...</td>\n",
       "      <td>illegals dump kids border like road kill refus...</td>\n",
       "      <td>illegals dump kids border like road kill refus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>ny times: 'nearly all white' states pose 'an a...</td>\n",
       "      <td>ny times nearly all white states pose an array...</td>\n",
       "      <td>ny times nearly white states pose array proble...</td>\n",
       "      <td>ny times nearly white states pose array proble...</td>\n",
       "      <td>ny times nearly white states pose array proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>orban in brussels: european leaders are ignori...</td>\n",
       "      <td>orban in brussels european leaders are ignorin...</td>\n",
       "      <td>orban brussels european leaders ignoring peopl...</td>\n",
       "      <td>orban brussels european leaders ignoring peopl...</td>\n",
       "      <td>orban brussels european leaders ignoring peopl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hurray, saving us $$$ in so many ways @potus @...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2  @KamalaHarris Illegals Dump their Kids at the ...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Hurray, saving us $$$ in so many ways   #LockT...   \n",
       "1  Why would young fighting age men be the vast m...   \n",
       "2   Illegals Dump their Kids at the border like R...   \n",
       "3  NY Times: 'Nearly All White' States Pose 'an A...   \n",
       "4  Orban in Brussels: European leaders are ignori...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  hurray, saving us $$$ in so many ways   #lockt...   \n",
       "1  why would young fighting age men be the vast m...   \n",
       "2   illegals dump their kids at the border like r...   \n",
       "3  ny times: 'nearly all white' states pose 'an a...   \n",
       "4  orban in brussels: european leaders are ignori...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  hurray saving us  in so many ways   lockthemup...   \n",
       "1  why would young fighting age men be the vast m...   \n",
       "2   illegals dump their kids at the border like r...   \n",
       "3  ny times nearly all white states pose an array...   \n",
       "4  orban in brussels european leaders are ignorin...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  hurray saving us many ways lockthemup buildthe...   \n",
       "1  would young fighting age men vast majority one...   \n",
       "2  illegals dump kids border like road kill refus...   \n",
       "3  ny times nearly white states pose array proble...   \n",
       "4  orban brussels european leaders ignoring peopl...   \n",
       "\n",
       "                                       text_wo_urlno  \\\n",
       "0  hurray saving us many ways lockthemup buildthe...   \n",
       "1  would young fighting age men vast majority one...   \n",
       "2  illegals dump kids border like road kill refus...   \n",
       "3  ny times nearly white states pose array proble...   \n",
       "4  orban brussels european leaders ignoring peopl...   \n",
       "\n",
       "                                      text_wo_htmlno  \n",
       "0  hurray saving us many ways lockthemup buildthe...  \n",
       "1  would young fighting age men vast majority one...  \n",
       "2  illegals dump kids border like road kill refus...  \n",
       "3  ny times nearly white states pose array proble...  \n",
       "4  orban brussels european leaders ignoring peopl...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "df[\"text_wo_htmlno\"] = df[\"text_wo_urlno\"].apply(lambda text: remove_html(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJR_fP8Pjuca"
   },
   "source": [
    "REMOVE DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lOoVNHv2jt76"
   },
   "outputs": [],
   "source": [
    "#df['text_wo_digitno'] = df['text_wo_urlno'].apply(lambda x: re.sub('W*dw*','',x))\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPukdQXDkMZt"
   },
   "source": [
    "LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "-Sv4nhZmkL0p",
    "outputId": "0332b0c7-3e1e-44c2-dce3-7caefc407e02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sanghita\n",
      "[nltk_data]     Chakraborty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Sanghita Chakraborty/nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Sanghita Chakraborty/nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5189b29badb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlemmatizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mwordnet_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"N\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"V\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVERB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"J\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADJ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"R\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADV\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mpos_tagged_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Sanghita Chakraborty/nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Sanghita Chakraborty\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"text_wo_htmlno\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kKe6YsjQkqMB",
    "outputId": "fd8ae230-98db-4127-8cb1-535b7dcb5342"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatizer.lemmatize(\"running\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMQKNX0wkt3p",
    "outputId": "420473a4-3d50-4347-a5b8-669bbdf57869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.tolist of 0       hurray save u many way lockthemup buildthewall...\n",
       "1       would young fight age men vast majority one es...\n",
       "2       illegals dump kid border like road kill refuse...\n",
       "3       ny time nearly white state pose array problem ...\n",
       "4       orban brussels european leader ignore people w...\n",
       "                              ...                        \n",
       "8995                               proud hysterical woman\n",
       "8996    hollywood complicit rape sexual assault woman ...\n",
       "8997    fuck cunt hate see kid get neglect used parent...\n",
       "8998                                hysterical woman like\n",
       "8999    nearly every woman know metoo fee sexual harre...\n",
       "Name: text_lemmatized, Length: 9000, dtype: object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['text_lemmatized'].to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzjUO445oJS7"
   },
   "source": [
    "TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1wRiYmFoKtD",
    "outputId": "7c2714fa-3526-4b5b-cb9c-451e512d3a4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Sanghita\n",
      "[nltk_data]     Chakraborty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text_lemmatized'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text_lemmatized'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1e80c07ec994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'punkt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnltk_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text_lemmatized\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#df.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text_lemmatized'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk_token = df[\"text_lemmatized\"].apply(lambda text:  nltk.word_tokenize(text))\n",
    "#df.head()\n",
    "print(nltk_token)\n",
    "#nltk_tokens = nltk.sent_tokenize(df['text_lemmatized'])\n",
    "#print (nltk_tokens)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing the words:\n",
    "final_text = "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NLP_G32.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
